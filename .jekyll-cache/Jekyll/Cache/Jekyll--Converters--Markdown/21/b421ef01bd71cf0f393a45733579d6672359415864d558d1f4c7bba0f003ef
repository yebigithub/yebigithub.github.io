I"Ï<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Aut/title-480.webp" />
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Aut/title-800.webp" />
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Aut/title-1400.webp" />
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/Aut/title.png" class="img-fluid rounded z-depth-0" width="auto" height="auto" title="title" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture>

</figure>

    </div>
</div>

<p><a href="https://doi.org/10.1093/tas/txac163">https://doi.org/10.1093/tas/txac163</a></p>

<p><strong>Abstract</strong><br />
Animal dimensions are essential indicators for monitoring their growth rate, diet efficiency, and health status. A computer vision system is a recently emerging precision livestock farming technology that overcomes the previously unresolved challenges pertaining to labor and cost. Depth sensor cameras can be used to estimate the depth or height of an animal, in addition to two-dimensional information. Collecting top-view depth images is common in evaluating body mass or conformational traits in livestock species. However, in the depth image data acquisition process, manual interventions are involved in controlling a camera from a laptop or where detailed steps for automated data collection are not documented. Furthermore, open-source image data acquisition implementations are rarely available. The objective of this study was to 1) investigate the utility of automated top-view dairy cow depth data collection methods using picture- and video-based methods, 2) evaluate the performance of an infrared cut lens, 3) and make the source code available. Both methods can automatically perform animal detection, trigger recording, capture depth data, and terminate recording for individual animals. The picture-based method takes only a predetermined number of images whereas the video-based method uses a sequence of frames as a video. For the picture-based method, we evaluated 3- and 10-picture approaches. The depth sensor camera was mounted 2.75 m above-the-ground over a walk-through scale between the milking parlor and the free-stall barn. A total of 150 Holstein and 100 Jersey cows were evaluated. A pixel location where the depth was monitored was set up as a point of interest. More than 89% of cows were successfully captured using both picture- and video-based methods. The success rates of the picture- and video-based methods further improved to 92% and 98%, respectively, when combined with an infrared cut lens. Although both the picture-based method with 10 pictures and the video-based method yielded accurate results for collecting depth data on cows, the former was more efficient in terms of data storage. The current study demonstrates automated depth data collection frameworks and a Python implementation available to the community, which can help facilitate the deployment of computer vision systems for dairy cows.</p>

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Aut/fig1-480.webp" />
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Aut/fig1-800.webp" />
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Aut/fig1-1400.webp" />
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/Aut/fig1.jpeg" class="img-fluid rounded z-depth-0" width="auto" height="auto" title="cv1" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture>

</figure>

    </div>

</div>
<div class="caption">
FIGURE 1. Single-and multi-environment genomic prediction cross-validation scenarios. (A) Single-environment analysis, (B) All the lines in one environment were used to predict the same lines in a new environment (CV0), (C) Performance of new lines that are not phenotyped in any environment was predicted through the genetic relationship with other lines (CV1), and (D) Predict lines that were evaluated in only one environment through the genetic and environmental relationships (CV2).
</div>

<div class="row">
    <div class="col-sm mt-3 mt-md-3">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Sea1/fig2-480.webp" />
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Sea1/fig2-800.webp" />
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Sea1/fig2-1400.webp" />
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/Sea1/fig2.png" class="img-fluid rounded z-depth-0" width="auto" height="auto" title="cv2" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture>

</figure>

    </div>

</div>
<div class="caption">
FIGURE 2. Single-environment prediction accuracies of the nine agronomic sesame traits in 2018 (A) and 2020 (B) growing seasons using genomic best linear unbiased prediction (GBLUP), BayesB, BayesC, and reproducing kernel Hilbert spaces regression (RKHS). Flowering date (FD), height to the first capsule (HTFC), plant height (PH), reproductive zone (RZ), reproductive index (RI), number of branches per plant (NBPP), seed-yield per plant (SYPP), seeds number per plant (SNPP), and thousand-seed weight (TSW).
</div>

<div class="row">
    <div class="col-sm mt-3 mt-md-0 d-flex align-items-center">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Sea1/fig3-480.webp" />
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Sea1/fig3-800.webp" />
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Sea1/fig3-1400.webp" />
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/Sea1/fig3.png" class="img-fluid rounded z-depth-0" width="auto" height="auto" title="fig3" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture>

</figure>

    </div>
</div>
<div class="caption">
FIGURE 3. Proportion of the main genetic variance (main effect), environment-specific variance (specific effect), and residual variance components for each trait obtained from the marker-by-environment interaction model. Flowering date (FD), height to the first capsule (HTFC), plant height (PH), reproductive zone (RZ), reproductive index (RI), number of branches per plant (NBPP), seed-yield per plant (SYPP), seeds number per plant (SNPP), and thousand-seed weight (TSW).
</div>

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Sea1/fig4-480.webp" />
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Sea1/fig4-800.webp" />
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Sea1/fig4-1400.webp" />
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/Sea1/fig4.png" class="img-fluid rounded z-depth-0" width="auto" height="auto" title="fig4" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture>

</figure>

    </div>
</div>
<div class="caption">
FIGURE 4. Multi-environment genomic prediction accuracies of the nine agronomic sesame traits using the best linear unbiased prediction model when all the lines in one environment were used to predict the same lines in a new environment (CV0). Flowering date (FD), height to the first capsule (HTFC), plant height (PH), reproductive zone (RZ), reproductive index (RI), number of branches per plant (NBPP), seed-yield per plant (SYPP), seeds number per plant (SNPP), and thousand-seed weight (TSW).
</div>
:ET